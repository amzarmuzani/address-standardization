{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ae4cf64",
   "metadata": {},
   "source": [
    "# P1/P2 Mapping\n",
    "     1. Use unmapped account + address from #1 and map P1 SDU\n",
    "     2. Use unmapped account + address from #2 and map P2 SDU\n",
    "     \n",
    "Note, this notebook was created on 13.12.2022. The below codes were originally copied from the AWS Glue Job: amzar-address_standardization-prod-process_gapi_tm on 13.12.2022 at 11.30am with the intention of uploading directly to Amzar's GitHub to keep a version of this before any edits on AWS Glue (version control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## on 9/9/2022 - Fakhrul and I agreed for me to change the lines which could potentially give SettingWithCopyWarnings i.e replacing lines which use double bracket with .loc methods \n",
    "## I decided to add loc to lines which give both warnings and those where the LHS & RHS of the assignment step does not have the same column i.e I won't add loc to df['COL'] = df['COL'].str.upper()\n",
    "## on 9/9/2022 - I also added .copy() to steps where it's just df1 = df i.e this would now be df1 = df.copy()\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ### P1/P2 Mapping\n",
    "#      1. Run similarity using fuzzy wuzzy and map P1 MDU\n",
    "#      2. Use unmapped account + address from #1 and map P1 SDU\n",
    "#      3. Use unmapped account + address from #2 and map P2 SDU\n",
    "\n",
    "## import section\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import resource\n",
    "import awswrangler as wr\n",
    "# For similarity\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import time\n",
    "import sys\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from datetime import datetime\n",
    "args = getResolvedOptions(sys.argv,\n",
    "                          ['job_name',\n",
    "                           'ISP_Name',\n",
    "                           'isp_new_std_path',\n",
    "                           'astro_new_std_path',\n",
    "                           'uams_mdu_path',\n",
    "                           'uams_sdu_path',\n",
    "                           'temp_isp_corrected_save_path'])\n",
    "\n",
    "ISP_Name = args['ISP_Name']\n",
    "isp_new_std_path = args['isp_new_std_path'] #new std path\n",
    "astro_new_std_path = args['astro_new_std_path'] #new std path\n",
    "uams_mdu_path = args['uams_mdu_path'] #pipeline bucket # Save in pipeline bucket - to be used in UAMS generation\n",
    "uams_sdu_path = args['uams_sdu_path'] #pipeline bucket # Save in pipeline bucket - to be used in UAMS generation                           \n",
    "temp_isp_corrected_save_path = args['temp_isp_corrected_save_path']\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "## Run this notebook for all ISPs\n",
    "ISP_Name = 'TM'\n",
    "# ISP_Name = 'ALLO'\n",
    "# ISP_Name = 'Maxis'\n",
    "# ISP_Name = 'CTS'\n",
    "\n",
    "## Amzar 9/9/2022 -> added a datetime key for tracking file creation\n",
    "curr_date = str(pd.datetime.today().strftime('%Y%m%d'))\n",
    "# curr_date = '20220909' --> used this line the first night I ran this Glue job\n",
    "print('Date notebook was run & files were created', curr_date)\n",
    "\n",
    "# ### ---------------------------------------------------- P1 MDU Mapping - MDU --------------------------------------------------------------------   \n",
    "\n",
    "import pandas as pd\n",
    "# %cd /Users/zmmzohreh/OneDrive - MEASAT Broadcast Network Systems Sdn. Bhd/Shared Documents/Input Data\n",
    "#get_ipython().run_line_magic('cd', '/Users/zmmzohreh/OneDrive - MEASAT Broadcast Network Systems Sdn. Bhd/Shared Documents/Fakhrul')\n",
    "\n",
    "print('reading tm')\n",
    "\n",
    "isp_corrected = wr.s3.read_csv(path = isp_new_std_path, usecols = ['Combined_Building','HouseNo',\n",
    "'Street_1','Street_2','AREA','STD_CITY','STATE', 'POSTCODE', 'ServiceType','Standard_Building_Name','match'], \n",
    "dtype= str, compression='gzip') # Amzar 10/9/2022 --> added reading in the file as dtype = str. 14/10/2022 --> added compression='gzip' as TM_New_Std was saved as gzip due to large file size\n",
    "\n",
    "# astro_corrected = pd.read_csv('Astro_New_Standardised.csv')\n",
    "#astro_corrected = pd.read_csv('astro_new_standardized.csv', usecols = ['service_add_objid', 'ACCOUNT_NO','HOUSE_NO', 'AREA', 'STD_CITY',\n",
    "                                #'ASTRO_STATE', 'POSTCODE', 'Combined_Building','Street_1',\n",
    "                                 #'Street_2','Standard_Building_Name','Source','match'], engine='python', error_bad_lines=False)\n",
    "\n",
    "print('reading astro')\n",
    "\n",
    "astro_corrected = wr.s3.read_csv(astro_new_std_path, usecols = ['ACCOUNT_NO','service_add_objid','HOUSE_NO','Combined_Building','Street_1', 'Street_2','Standard_Building_Name','AREA','POSTCODE','STD_CITY','ASTRO_STATE', 'Source', 'match'], dtype= str) # Amzar 10/9/2022 --> added reading in the file as dtype = str\n",
    "\n",
    "\n",
    "print('this is tm corrected shape: ', isp_corrected.shape)\n",
    "print('this is astro corrected shape: ', astro_corrected.shape)\n",
    "\n",
    "isp_corrected.Combined_Building.unique()\n",
    "isp_corrected.head()\n",
    "\n",
    "# print(isp_corrected.shape,astro_corrected.shape) # Amzar 9/9/2022 --> commented out coz duplicate of above print step\n",
    "\n",
    "isp_corrected.info()\n",
    "\n",
    "isp_corrected.head()\n",
    "\n",
    "astro_corrected.info()\n",
    "\n",
    "astro_corrected = astro_corrected.drop_duplicates()\n",
    "print('Astro Corrected Shape after first dedupe on all columns, keep first: ', astro_corrected.shape, 'Astro Unique Account No: ', astro_corrected.ACCOUNT_NO.nunique()) # Amzar 9/9/2022 --> added more words to the print statement for easier tracking\n",
    "\n",
    "astro_corrected.head()\n",
    "\n",
    "isp_corrected.Combined_Building.unique()\n",
    "\n",
    "## Updated after sharing\n",
    "# Capitalize all G_Condo and G_City form both isp_corrected and astro_corrected\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.upper()\n",
    "isp_corrected['Street_1'] = isp_corrected['Street_1'].str.upper()\n",
    "isp_corrected['Combined_Building'] = isp_corrected['Combined_Building'].astype(str).str.upper()\n",
    "isp_corrected['STD_CITY'] = isp_corrected['STD_CITY'].str.upper()\n",
    "\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.upper()\n",
    "astro_corrected['Street_1'] = astro_corrected['Street_1'].str.upper()\n",
    "astro_corrected['Combined_Building'] = astro_corrected['Combined_Building'].astype(str).str.upper()\n",
    "astro_corrected['STD_CITY'] = astro_corrected['STD_CITY'].str.upper()\n",
    "\n",
    "isp_corrected['Combined_Building'].unique()\n",
    "\n",
    "isp_corrected.head()\n",
    "\n",
    "# Fix HOUSE_NO\n",
    "astro_corrected[\"HOUSE_NO\"] = astro_corrected['HOUSE_NO'].str.replace('nan ','', case = False)\n",
    "astro_corrected[\"HOUSE_NO\"] = astro_corrected[\"HOUSE_NO\"].str.replace('[,.]','', case = False)\n",
    "astro_corrected[\"HOUSE_NO\"] = astro_corrected[\"HOUSE_NO\"].str.replace(\"[\",'')\n",
    "astro_corrected[\"HOUSE_NO\"] = astro_corrected[\"HOUSE_NO\"].str.replace(\"]\",\"\")\n",
    "astro_corrected[\"HOUSE_NO\"] = astro_corrected[\"HOUSE_NO\"].str.replace(\"'\",\"\", case = False)\n",
    "astro_corrected[\"HOUSE_NO\"] = astro_corrected[\"HOUSE_NO\"].str.replace(\"NO. \",\"\", case = False)\n",
    "astro_corrected[\"HOUSE_NO\"] = astro_corrected[\"HOUSE_NO\"].str.replace(\"NO.\",\"\", case = False)\n",
    "astro_corrected[\"HOUSE_NO\"] = astro_corrected[\"HOUSE_NO\"].str.replace(\"NO\",\"\", case = False)\n",
    "astro_corrected[\"HOUSE_NO\"] = astro_corrected[\"HOUSE_NO\"].str.replace(\"LOT\",\"\", case = False)\n",
    "astro_corrected[\"HOUSE_NO\"] = astro_corrected[\"HOUSE_NO\"].str.replace(\"UNIT\",\"\", case = False)\n",
    "astro_corrected[\"HOUSE_NO\"] = astro_corrected[\"HOUSE_NO\"].str.replace(\",\",\"\", case = False)\n",
    "astro_corrected[\"HOUSE_NO\"] = astro_corrected[\"HOUSE_NO\"].str.replace(\"\\.\",\"\", case = False)\n",
    "astro_corrected[\"HOUSE_NO\"] = astro_corrected[\"HOUSE_NO\"].str.replace(\"BLOCK\",\"\", case = False)\n",
    "astro_corrected[\"HOUSE_NO\"] = astro_corrected[\"HOUSE_NO\"].str.replace(\"BLOK\",\"\", case = False)\n",
    "astro_corrected[\"HOUSE_NO\"] = astro_corrected[\"HOUSE_NO\"].str.replace(\"BLK\",\"\", case = False)\n",
    "\n",
    "# Fix HOUSE_NO that are converted to date\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"JAN-\",\"01-\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"-JAN\",\"-01\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace('FEB-','02-', case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace('-FEB','-02', case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"MAR-\",'03-', case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"-MAR\",\"-03\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"APR-\",\"04-\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"-APR\",\"-04\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"MAY-\",\"05-\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"-MAY\",\"-05\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"JUN-\",\"06-\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"-JUN\",\"-06\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace('JUL-','07-', case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace('-JUL','-07', case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"AUG-\",'08-', case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"-AUG\",\"-08\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"SEP-\",\"09-\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"-SEP\",\"-09\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"OCT-\",\"10-\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"-OCT\",\"-10\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"NOV-\",\"11-\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"-NOV\",\"-11\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"DEC-\",\"12-\", case = False)\n",
    "astro_corrected['HOUSE_NO'] = astro_corrected['HOUSE_NO'].str.replace(\"-DEC\",\"-12\", case = False)\n",
    "\n",
    "\n",
    "astro_corrected[\"COMBINED_ADD\"] = astro_corrected[\"HOUSE_NO\"].map(str) + \"  ,\" +                             astro_corrected[\"Combined_Building\"].map(str) + \"  ,\" +                             astro_corrected[\"Street_1\"].map(str) + \"  ,\" +                             astro_corrected[\"AREA\"].map(str) + \" ,\" +                             astro_corrected[\"POSTCODE\"].map(str) + \" ,\" +                             astro_corrected[\"STD_CITY\"].map(str)+ \" ,\" +                             astro_corrected[\"ASTRO_STATE\"].map(str)\n",
    "\n",
    "\n",
    "astro_corrected['ASTRO_HOUSE_NO1']= astro_corrected['HOUSE_NO'].str.pad(width=10)\n",
    "\n",
    "\n",
    "# Add new column in astro_corrected -- G_Condo + G_City = HNUM_STRT\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected[\"Combined_Building\"].map(str) + \" ,\" +astro_corrected[\"STD_CITY\"].map(str)\n",
    "astro_corrected.head()\n",
    "\n",
    "# Clean HNUM_STRT column\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected['HNUM_STRT'].str.replace('nan ','', case = False)\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected['HNUM_STRT'].str.replace('[,.]','', case = False)\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected[\"HNUM_STRT\"].str.replace(\" \",\"\")\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected[\"HNUM_STRT\"].str.replace(\"\\.\",\"\")\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected[\"HNUM_STRT\"].str.replace(\",\",\"\")\n",
    "\n",
    "print('Astro corrected shape after cleaning address columns & creating HNUM_STRT: ', astro_corrected.shape) # Amzar 9/9/2022 --> added more text to print statement \n",
    "\n",
    "\n",
    "# Capitalize HNUM_STRT\n",
    "astro_corrected['HNUM_STRT'] = astro_corrected['HNUM_STRT'].str.upper() \n",
    "\n",
    "# astro_corrected.head()\n",
    "\n",
    "\n",
    "# Fix house no for isp_corrected\n",
    "isp_corrected[\"HouseNo\"] = isp_corrected['HouseNo'].str.replace('nan ','', case = False)\n",
    "isp_corrected[\"HouseNo\"] = isp_corrected[\"HouseNo\"].str.replace('[,.]','', case = False)\n",
    "isp_corrected[\"HouseNo\"] = isp_corrected[\"HouseNo\"].str.replace(\"[\",'', )\n",
    "isp_corrected[\"HouseNo\"] = isp_corrected[\"HouseNo\"].str.replace(\"]\",\"\")\n",
    "isp_corrected[\"HouseNo\"] = isp_corrected[\"HouseNo\"].str.replace(\"'\",\"\", case = False)\n",
    "isp_corrected[\"HouseNo\"] = isp_corrected[\"HouseNo\"].str.replace(\"NO. \",\"\", case = False)\n",
    "isp_corrected[\"HouseNo\"] = isp_corrected[\"HouseNo\"].str.replace(\"NO.\",\"\", case = False)\n",
    "isp_corrected[\"HouseNo\"] = isp_corrected[\"HouseNo\"].str.replace(\"NO\",\"\", case = False)\n",
    "isp_corrected[\"HouseNo\"] = isp_corrected[\"HouseNo\"].str.replace(\"LOT\",\"\", case = False)\n",
    "isp_corrected[\"HouseNo\"] = isp_corrected[\"HouseNo\"].str.replace(\"UNIT\",\"\", case = False)\n",
    "isp_corrected[\"HouseNo\"] = isp_corrected[\"HouseNo\"].str.replace(\",\",\"\", case = False)\n",
    "isp_corrected[\"HouseNo\"] = isp_corrected[\"HouseNo\"].str.replace(\"\\.\",\"\", case = False)\n",
    "isp_corrected[\"HouseNo\"] = isp_corrected[\"HouseNo\"].str.replace(\"BLOCK\",\"\", case = False)\n",
    "isp_corrected[\"HouseNo\"] = isp_corrected[\"HouseNo\"].str.replace(\"BLOK\",\"\", case = False)\n",
    "isp_corrected[\"HouseNo\"] = isp_corrected[\"HouseNo\"].str.replace(\"BLK\",\"\", case = False)\n",
    "\n",
    "\n",
    "# Fix HouseNo that are converted to date\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"JAN-\",\"01-\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"-JAN\",\"-01\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace('FEB-','02-', case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace('-FEB','-02', case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"MAR-\",'03-', case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"-MAR\",\"-03\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"APR-\",\"04-\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"-APR\",\"-04\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"MAY-\",\"05-\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"-MAY\",\"-05\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"JUN-\",\"06-\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"-JUN\",\"-06\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace('JUL-','07-', case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace('-JUL','-07', case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"AUG-\",'08-', case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"-AUG\",\"-08\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"SEP-\",\"09-\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"-SEP\",\"-09\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"OCT-\",\"10-\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"-OCT\",\"-10\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"NOV-\",\"11-\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"-NOV\",\"-11\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"DEC-\",\"12-\", case = False)\n",
    "isp_corrected['HouseNo'] = isp_corrected['HouseNo'].str.replace(\"-DEC\",\"-12\", case = False)\n",
    "\n",
    "isp_corrected['TM_HOUSE_NO1']= isp_corrected['HouseNo'].str.pad(width=10)\n",
    "\n",
    "isp_corrected.Combined_Building.unique()\n",
    "\n",
    "isp_corrected.head()\n",
    "\n",
    "# Add new column in isp_corrected -- G_Condo + G_City = HNUM_STRT_TM\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected[\"Combined_Building\"].map(str) + \" ,\" + isp_corrected[\"STD_CITY\"].map(str)\n",
    "isp_corrected.head()\n",
    "\n",
    "isp_corrected.Combined_Building.unique()\n",
    "\n",
    "\n",
    "# Clean HNUM_STRT_TM column\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected['HNUM_STRT_TM'].str.replace('nan ','', case = False)\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected['HNUM_STRT_TM'].str.replace('[,.]','', case = False)\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected[\"HNUM_STRT_TM\"].str.replace(\" \",\"\")\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected[\"HNUM_STRT_TM\"].str.replace(\",\",\"\")\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected[\"HNUM_STRT_TM\"].str.replace(\"\\.\",\"\")\n",
    "\n",
    "print('TM corrected shape after cleaning address columns & creating HNUM_STRT_TM: ', isp_corrected.shape) # Amzar 9/9/2022 --> added more text to print statement\n",
    "\n",
    "isp_corrected.head()\n",
    "\n",
    "# Capitalize HNUM_STRT_TM\n",
    "isp_corrected['HNUM_STRT_TM'] = isp_corrected['HNUM_STRT_TM'].str.upper() \n",
    "\n",
    "# Remove nulls in HNUM_STRT and HNUM_STRT_TM\n",
    "astro_corrected = astro_corrected[astro_corrected.HNUM_STRT.notnull()] # # Amzar 9/9/2022 --> this is the last transformation to astro_corrected before the end of P1 MDU step. So before going to P1 SDU mapping, we may actually be missing some addresses as we transfer astro_corrected to astro_unmapped\n",
    "isp_corrected = isp_corrected[isp_corrected.HNUM_STRT_TM.notnull()]\n",
    "\n",
    "print('Astro corrected shape after filtering out null HNUM_STRT: ', astro_corrected.shape) # Amzar 9/9/2022 --> added more text to print statement\n",
    "print('TM corrected shape after filtering out null HNUM_STRT_TM: ', isp_corrected.shape) # Amzar 9/9/2022 --> added more text to print statement\n",
    "\n",
    "\n",
    "#REMOVE DUPLICATES. Line 1 (words) creates a list of ALL HNUM_STRT_TM. Line 2 (selection) only keeps unique HNUM_STRT_TM\n",
    "words = \" \".join(isp_corrected.HNUM_STRT_TM).split() # default splits on whitespace\n",
    "selection = set(words)\n",
    "selection1 = list(selection)\n",
    "selection2 = pd.DataFrame(selection1)\n",
    "selection2.columns = ['MAPPED_HNUM_STRT_TM']\n",
    "selection2.head()\n",
    "\n",
    "len(selection2)\n",
    "\n",
    "# JOIN astro_corrected to isp_corrected but only those with matching HNUM_STRT\n",
    "MAPPED_STRT_HNUM_Df = astro_corrected.merge(selection2,left_on ='HNUM_STRT', right_on = 'MAPPED_HNUM_STRT_TM', how = 'inner')\n",
    "MAPPED_STRT_HNUM_Df.shape\n",
    "\n",
    "MAPPED_STRT_HNUM_Df.head()\n",
    "\n",
    "# After merge, the Combined_Building in MAPPED_STRT_HNUM_Df is from astro_corrected\n",
    "MAPPED_STRT_HNUM_Df.Combined_Building.unique()\n",
    "\n",
    "MAPPED_STRT_HNUM_Df.head()\n",
    "\n",
    "\n",
    "MAPPED_STRT_HNUM_Df.head()\n",
    "\n",
    "MAPPED_STRT_HNUM_Df.Combined_Building.unique()\n",
    "\n",
    "MAPPED_STRT_HNUM_Df.info()\n",
    "\n",
    "MAPPED_STRT_HNUM_Df.Combined_Building.unique()\n",
    "\n",
    "\n",
    "# Making sure that G_Condo has valid value ## 28.9.2022 - not sure why this comment says G_Condo... Maybe this is why Rev was confused, coz she thinks that P1 MDU NEEDS to be mapped to a standardized vendor list - but in the codes below, we're checking that Combined_Building has valid value\n",
    "MAPPED_STRT_HNUM_Df[\"Combined_Building\"] = MAPPED_STRT_HNUM_Df['Combined_Building'].str.replace('[,.]','', case = False)\n",
    "MAPPED_STRT_HNUM_Df[\"Combined_Building\"] = MAPPED_STRT_HNUM_Df[\"Combined_Building\"].str.replace(\",\",\"\")\n",
    "\n",
    "# Removing those with null Combined_Building (for P1 MDU)\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['Combined_Building'].notnull()]\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['Combined_Building']!= \"\"]\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['Combined_Building']!= \" \"]\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['Combined_Building']!= \"NAN\"]\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['Combined_Building']!= \"nan\"]\n",
    "MAPPED_STRT_HNUM_Df.shape\n",
    "\n",
    "\n",
    "## Cleaning of Street Name\n",
    "MAPPED_STRT_HNUM_Df.loc[MAPPED_STRT_HNUM_Df[\"Street_1\"]=='nan',\"Street_1\"] = ''\n",
    "MAPPED_STRT_HNUM_Df.loc[MAPPED_STRT_HNUM_Df[\"Street_1\"]=='NAN',\"Street_1\"] = ''\n",
    "\n",
    "# --> is this a repeat code of earlier step?\n",
    "MAPPED_STRT_HNUM_Df[\"Combined_Building\"] = MAPPED_STRT_HNUM_Df['Combined_Building'].str.replace('[,.]','', case = False)\n",
    "\n",
    "\n",
    "MAPPED_STRT_HNUM_Df.Combined_Building.unique()\n",
    "\n",
    "MAPPED_STRT_HNUM_Df.head()\n",
    "\n",
    "MAPPED_STRT_HNUM_Df['ACCOUNT_NO'].nunique()\n",
    "\n",
    "# this step is to keep only ONE record for 1 address even if there are 2 Sources (Vendor or GAPI)\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df.sort_values(by='Source', ascending=False)\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df.drop_duplicates(subset=['ACCOUNT_NO','HOUSE_NO'],keep='first')\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df.drop_duplicates(subset='ACCOUNT_NO',keep='last')\n",
    "\n",
    "print('P1 MDU MAPPED_STRT_HNUM_Df - Shape: ', MAPPED_STRT_HNUM_Df.shape, ' & Unique Acc_No: ', MAPPED_STRT_HNUM_Df.ACCOUNT_NO.nunique()) # Amzar 9/9/2022 --> added more text to print statement \n",
    "\n",
    "MAPPED_STRT_HNUM_Df['ACCOUNT_NO'].nunique()\n",
    "\n",
    "MAPPED_STRT_HNUM_Df.info()\n",
    "\n",
    "## Amzar 10/9/2022 --> Found that these 2 lines below ONLY happens for P1 MDU mapping step. It may be why we had issues of 1 acc_no having more than 1 P1P2 MDU/SDU tag (fixed by reading in all files as dtype=str)\n",
    "MAPPED_STRT_HNUM_Df['ACCOUNT_NO'] = MAPPED_STRT_HNUM_Df['ACCOUNT_NO'].astype(str)\n",
    "MAPPED_STRT_HNUM_Df['ACCOUNT_NO'] = MAPPED_STRT_HNUM_Df['ACCOUNT_NO'].str.replace('\\.0','', case = False)\n",
    "\n",
    "P1_MDU = MAPPED_STRT_HNUM_Df.copy() # Amzar 9/9/2022 --> added copy() to create an explicit copy\n",
    "\n",
    "print('P1_MDU dataframe shape: ', P1_MDU.shape) # Amzar 9/9/2022 --> added new print statement to see shape of P1_MDU variable\n",
    "\n",
    "isp_corrected.info() # not sure why this is here\n",
    "\n",
    "\n",
    "# ### Generating UAMS format and getting ServiceType\n",
    "\n",
    "\n",
    "STRT_P1 = MAPPED_STRT_HNUM_Df.copy() # Amzar 9/9/2022 --> added copy() to create an explicit copy\n",
    "print('P1 MDU STRT_P1 dataframe shape: ', STRT_P1.shape) # Amzar 9/9/2022 --> added new print statement to see shape of STRT_P1 variable\n",
    "\n",
    "STRT_P1['Street_1'] = STRT_P1['Street_1'].astype(str)\n",
    "\n",
    "STRT_P1.reset_index(inplace=True, drop=True)\n",
    "test = STRT_P1.loc[STRT_P1['Street_1'].apply(lambda x: x.startswith('AA')), :].index # Amzar 9/9/2022 --> added loc statement\n",
    "test = list(test)\n",
    "\n",
    "STRT_P1.loc[test,'Street_1'] = ''\n",
    "\n",
    "STRT_P1.loc[STRT_P1['match']=='Match','Street_2'] = ''\n",
    "STRT_P1[STRT_P1['match']=='Match']\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_street(item):\n",
    "\n",
    "    street_type = \"\"\n",
    "    \n",
    "    r1 = \"JALAN|LORONG|CHANGKAT|LAMAN|LAHAT|LEBUH|LEBUHRAYA|LENGKOK|LINGKARAN|PERSIARAN\"\n",
    "\n",
    "\n",
    "    m = re.search(r1,item)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "    return street_type        \n",
    "        \n",
    "STRT_P1[\"Street_Type_1\"] = STRT_P1[\"Street_1\"].apply(extract_street)\n",
    "STRT_P1[\"Street_Type_2\"] = STRT_P1[\"Street_2\"].map(str).apply(extract_street)\n",
    "STRT_P1.head()\n",
    "\n",
    "street_type_list = ['JALAN ', 'LORONG ','CHANGKAT ', 'LAMAN ', 'LAHAT ', 'LEBUH ', 'LEBUHRAYA ', 'LENGKOK ','LINGKARAN ', 'PERSIARAN ' ]\n",
    "STRT_P1[\"Street_1_New\"] = STRT_P1[\"Street_1\"].str.replace('|'.join(street_type_list), '')\n",
    "\n",
    "STRT_P1[\"Street_2\"] = STRT_P1[\"Street_2\"].str.upper()\n",
    "STRT_P1[\"Street_2_New\"] = STRT_P1[\"Street_2\"].str.replace('|'.join(street_type_list), '')\n",
    "STRT_P1.head()\n",
    "\n",
    "## Getting the ServiceType---- 22Jun  >> remove ServiceType ERROR\n",
    "\n",
    "service_list = isp_corrected.loc[:, ['ServiceType','HNUM_STRT_TM']].drop_duplicates() # Amzar 9/9/2022 --> added loc \n",
    "service_list[\"ServiceType\"] = service_list[\"ServiceType\"].str.upper()\n",
    "service_list = service_list[service_list['ServiceType']!='ERROR']\n",
    "\n",
    "\n",
    "New_fields1 = pd.merge(STRT_P1,service_list,left_on ='HNUM_STRT',right_on='HNUM_STRT_TM', how = 'left')\n",
    "New_fields1.info()\n",
    "\n",
    "\n",
    "#MDU NEW\n",
    "New_fields2 = New_fields1[['ACCOUNT_NO','service_add_objid','ASTRO_HOUSE_NO1',\n",
    "                           'Combined_Building','Street_Type_1','Street_1_New','Standard_Building_Name', \n",
    "                           'Street_Type_2','Street_2_New','AREA','POSTCODE','STD_CITY','ASTRO_STATE', 'ServiceType', 'HNUM_STRT_TM']]\n",
    "\n",
    "\n",
    "New_fields2.loc[:, 'Servicable']= str(ISP_Name) # Amzar 9/9/2022 --> added loc \n",
    "\n",
    "\n",
    "## ---- 22Jun  >> keep both ServiceType FTTH/VDSL\n",
    "## ---- 22Jun  >> New_fields3 = New_fields2.drop_duplicates(subset= ['ACCOUNT_NO','ServiceType'], keep = 'first')\n",
    "\n",
    "\n",
    "New_fields3 = New_fields2.sort_values(['ServiceType']).drop_duplicates(subset= 'ACCOUNT_NO', keep = 'first')\n",
    "astro_cleaned = New_fields3.copy() # Amzar 9/9/2022 --> added copy()\n",
    "print('P1 MDU astro_cleaned shape: ', astro_cleaned.shape, '& New_fields3 shape: ', New_fields3.shape) # Amzar 9/9/2022 --> added new print statement to compare\n",
    "\n",
    "# Fix HOUSE_NO that are converted to date\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['ASTRO_HOUSE_NO1'] \n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"JAN-\",\"01-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-JAN\",\"-01\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Jan-\",\"01-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Jan\",\"-01\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"FEB-\",\"02-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-FEB\",'-02', case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Feb-\",\"02-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Feb\",\"-02\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"MAR-\",'03-', case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-MAR\",\"-03\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Mar-\",'03-', case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Mar\",\"-03\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"APR-\",\"04-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-APR\",\"-04\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Apr-\",\"04-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Apr\",\"-04\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"MAY-\",\"05-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-MAY\",\"-05\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"May-\",\"05-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-May\",\"-05\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"JUN-\",\"06-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-JUN\",\"-06\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Jun-\",\"06-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Jun\",\"-06\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"JUL-\",\"07-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-JUL\",\"-07\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Jul-\",\"07-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Jul\",\"-07\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"AUG-\",'08-', case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-AUG\",\"-08\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Aug-\",'08-', case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Aug\",\"-08\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"SEP-\",\"09-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-SEP\",\"-09\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Sep-\",\"09-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Sep\",\"-09\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"OCT-\",\"10-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-OCT\",\"-10\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Oct-\",\"10-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Oct\",\"-10\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"NOV-\",\"11-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-NOV\",\"-11\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Nov-\",\"11-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Nov\",\"-11\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"DEC-\",\"12-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-DEC\",\"-12\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Dec-\",\"12-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Dec\",\"-12\", case = False)\n",
    "\n",
    "# Fix HOUSE_NO that are converted to date (DD/MM/YYYY format)\n",
    "# Filter date HOUSE_NO\n",
    "date_house = astro_cleaned[astro_cleaned['HOUSE_NO'].str.match('^([0-2][0-9]|(3)[0-1])(\\/)(((0)[0-9])|((1)[0-2]))(\\/)\\d{4}$')== True]\n",
    "# Spliting the HOUSE_NO\n",
    "date_house.loc[:, 'block'] = (date_house.HOUSE_NO.str[0:2]) # Amzar 9/9/2022 --> added loc \n",
    "date_house.loc[:, 'floor'] = (date_house.HOUSE_NO.str[3:5]) # Amzar 9/9/2022 --> added loc \n",
    "date_house.loc[:, 'unit'] = (date_house.HOUSE_NO.str[8:10]) # Amzar 9/9/2022 --> added loc \n",
    "# Combine the split HOUSE_NO with -\n",
    "date_house.loc[:, 'HOUSE_NO_ASTRO'] = date_house['block'] + \"-\" + date_house['floor'] + \"-\" + date_house['unit'] # Amzar 9/9/2022 --> added loc \n",
    "# Filter not date HOUSE_NO\n",
    "not_date_house = astro_cleaned[~(astro_cleaned['HOUSE_NO'].str.match('^([0-2][0-9]|(3)[0-1])(\\/)(((0)[0-9])|((1)[0-2]))(\\/)\\d{4}$')== True)]\n",
    "not_date_house.loc[:, 'HOUSE_NO_ASTRO'] = not_date_house['HOUSE_NO'] # Amzar 9/9/2022 --> added loc \n",
    "not_date_house.head()\n",
    "# Append the 2 df again\n",
    "frame = [date_house,not_date_house]\n",
    "astro_cleaned = pd.concat(frame)\n",
    "astro_cleaned.shape\n",
    "\n",
    "# Remove additional column created to combine HOUSE_NO\n",
    "astro_cleaned = astro_cleaned.drop(['block','floor','unit'],axis=1)\n",
    "astro_cleaned.info()\n",
    "\n",
    "\n",
    "astro_cleaned['ASTRO_HOUSE_NO1']= astro_cleaned['HOUSE_NO_ASTRO'].str.pad(width=10)\n",
    "\n",
    "\n",
    "#MDU NEW\n",
    "astro_cleaned2 = astro_cleaned[['ACCOUNT_NO','service_add_objid', 'ASTRO_HOUSE_NO1', \n",
    "                                   'Combined_Building','Street_Type_1','Street_1_New','Street_Type_2',\n",
    "                                   'Street_2_New', 'AREA','STD_CITY' ,'POSTCODE', 'ASTRO_STATE',\n",
    "                                   'Standard_Building_Name',\n",
    "                                   'ServiceType', 'Servicable', 'HNUM_STRT_TM']]\n",
    "\n",
    "\n",
    "UAMS_MDU_Base = astro_cleaned2.copy() # Amzar 9/9/2022 --> added copy() \n",
    "print('P1 MDU UAMS_MDU_BASE df shape: ', UAMS_MDU_Base.shape, ' & astro_cleaned2 df shape: ', astro_cleaned2.shape) # Amzar 9/9/2022 --> added new print statement to compare\n",
    "\n",
    "UAMS_MDU_Base.loc[:, 'ACCOUNT_NO'] = UAMS_MDU_Base.loc[:, 'ACCOUNT_NO'].astype(str) # Amzar 9/9/2022 --> added loc \n",
    "UAMS_MDU_Base.loc[:, 'ACCOUNT_NO'] = UAMS_MDU_Base.loc[:, 'ACCOUNT_NO'].str.replace('\\.0','', case = False) # Amzar 9/9/2022 --> added loc \n",
    "\n",
    "print('P1 MDU UAMS_MDU_Base shape after converting ACC_NO col to str type: ', UAMS_MDU_Base.shape) # Amzar 9/9/2022 --> added more text to the print statement\n",
    "\n",
    "UAMS_MDU_Base = UAMS_MDU_Base.drop_duplicates(subset=['ACCOUNT_NO'], keep='first')\n",
    "print('P1 MDU UAMS_MDU_Base shape AFTER dedupe on ACC_NO, keep first: ', UAMS_MDU_Base.shape) # Amzar 9/9/2022 --> added more text to the print statement\n",
    "\n",
    "\n",
    "\n",
    "UAMS_MDU_Base=UAMS_MDU_Base.rename({'ASTRO_HOUSE_NO1':'House_No', \n",
    "                                      'ACCOUNT_NO': 'Account_No'}, axis=1)\n",
    "\n",
    "\n",
    "#UAMS_MDU_Base.to_csv('UAMS_Format_stndrd_'+str(ISP_Name)+'_P1_MDU.csv') # Save in pipeline bucket - to be used in UAMS generation\n",
    "\n",
    "print('this is p1 mdu: :', UAMS_MDU_Base.shape)\n",
    "wr.s3.to_csv(df = UAMS_MDU_Base, path = uams_mdu_path + 'UAMS_Format_stndrd_' + str(ISP_Name)+ '_P1_MDU.csv.gz', compression='gzip', index=False) # 18/11/22: AFTER running the job, decided to add this line to generate a file for easier automation. 5/12/22: added gz\n",
    "wr.s3.to_csv(df = UAMS_MDU_Base, path = uams_mdu_path + 'historical_folder/UAMS_Format_stndrd_' + str(ISP_Name)+ '_P1_MDU_' + str(curr_date) + '.csv.gz', compression='gzip', index=False) # 18/11/22: added underscore after 'MDU' and AFTER running it to generate the files, decided to add the dated one to historical_folder \n",
    "\n",
    "## revision - 31/5/22 - fakhrul - need to separate this process as it consumes too much memory\n",
    "wr.s3.to_csv(df = isp_corrected, path = temp_isp_corrected_save_path + 'temp_isp_corrected.csv.gz', index = False, compression='gzip') # 5/12/22: made this the automated version\n",
    "wr.s3.to_csv(df = isp_corrected, path = temp_isp_corrected_save_path + 'historical_folder/temp_isp_corrected_' + str(curr_date) + '.csv.gz', index = False, compression='gzip') # 18/11/22: added underscore after 'MDU'. 5/12/22: added gzip & historical_folder\n",
    "\n",
    "\n",
    "print('P1 MDU done')\n",
    "\n",
    "# Remove the mapped account no\n",
    "MAPPED_STRT_HNUM_Df_list = list(MAPPED_STRT_HNUM_Df['ACCOUNT_NO']) # all values here should be string already from above step\n",
    "astro_unmapped = astro_corrected.loc[~astro_corrected['ACCOUNT_NO'].isin(MAPPED_STRT_HNUM_Df_list), :] # Amzar 9/9/2022 --> added loc \n",
    "print('Astro Corrected shape right before end of P1 MDU mapping step and generating astro_unmapped: ', astro_corrected.shape) # Amzar 9/9/2022 --> added new print statement\n",
    "print('After P1 MDU mapping step --> Astro Unmapped Shape : ', astro_unmapped.shape, ' & no of Unique Account No: ', astro_unmapped.ACCOUNT_NO.nunique()) # Amzar 9/9/2022 --> added more text to the print statement\n",
    "\n",
    "\n",
    "# ### ---------------------------------------------------------- P1 SDU Mapping ----------------------------------------------------------\n",
    "\n",
    "## Using the unmapped base from P1 MDU mapping as the new astro_corrected\n",
    "astro_corrected = astro_unmapped.copy() # Amzar 9/9/2022 --> added copy()\n",
    "\n",
    "isp_corrected.info()\n",
    "\n",
    "print('Start of P1 SDU Mapping. First, check TM Corrected shape: ', isp_corrected.shape) # Amzar 9/9/2022 --> added more text to print statement \n",
    "print('astro_corrected shape for P1 SDU Mapping (unmapped base after P1 MDU Mapping): ', astro_corrected.shape) # Amzar 9/9/2022 --> added more text to print statement \n",
    "\n",
    "# astro_corrected.ACCOUNT_NO.nunique()\n",
    "\n",
    "\n",
    "# Add new column in astro_corrected -- HOUSE_NO + G_Street_Name_1 + G_City = HNUM_STRT\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected[\"HOUSE_NO\"].map(str) + \" ,\" +                             astro_corrected[\"Street_1\"].map(str) + \" ,\" +                             astro_corrected[\"STD_CITY\"].map(str)\n",
    "astro_corrected.tail()\n",
    "\n",
    "\n",
    "# Clean HNUM_STRT column\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected['HNUM_STRT'].str.replace('nan ','', case = False)\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected['HNUM_STRT'].str.replace('[,.]','', case = False)\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected[\"HNUM_STRT\"].str.replace(\" \",\"\")\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected[\"HNUM_STRT\"].str.replace(\"\\.\",\"\")\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected[\"HNUM_STRT\"].str.replace(\",\",\"\")\n",
    "\n",
    "print('Astro corrected shape after cleaning address columns & creating HNUM_STRT: ', astro_corrected.shape) # Amzar 9/9/2022 --> added more text to print statement \n",
    "\n",
    "\n",
    "# Capitalize HNUM_STRT\n",
    "astro_corrected['HNUM_STRT'] = astro_corrected['HNUM_STRT'].str.upper() \n",
    "\n",
    "\n",
    "astro_corrected.head()\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "# Add new column in isp_corrected -- HouseNo + G_Street_Name_1 + G_City = HNUM_STRT_TM\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected[\"HouseNo\"].map(str) + \" ,\" +                             isp_corrected[\"Street_1\"].map(str) + \" ,\" +                             isp_corrected[\"STD_CITY\"].map(str)\n",
    "isp_corrected.head()\n",
    "\n",
    "\n",
    "# Clean HNUM_STRT_TM column\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected['HNUM_STRT_TM'].str.replace('nan ','', case = False)\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected['HNUM_STRT_TM'].str.replace('[,.]','', case = False)\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected[\"HNUM_STRT_TM\"].str.replace(\" \",\"\")\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected[\"HNUM_STRT_TM\"].str.replace(\",\",\"\")\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected[\"HNUM_STRT_TM\"].str.replace(\"\\.\",\"\")\n",
    "\n",
    "print('TM corrected shape after cleaning address columns & creating HNUM_STRT_TM: ', isp_corrected.shape) # Amzar 9/9/2022 --> added more text to print statement\n",
    "\n",
    "\n",
    "# Capitalize HNUM_STRT_TM\n",
    "isp_corrected['HNUM_STRT_TM'] = isp_corrected['HNUM_STRT_TM'].str.upper() \n",
    "\n",
    "\n",
    "# Remove nulls in HNUM_STRT and HNUM_STRT_TM\n",
    "astro_corrected = astro_corrected[astro_corrected.HNUM_STRT.notnull()] # Amzar 9/9/2022 --> this is the last transformation to astro_corrected before the end of P1 MDU step. So before going to P1 SDU mapping, we may actually be missing some addresses as we transfer astro_corrected to astro_unmapped\n",
    "isp_corrected = isp_corrected[isp_corrected.HNUM_STRT_TM.notnull()]\n",
    "\n",
    "print('Astro corrected shape after filtering out null HNUM_STRT: ', astro_corrected.shape) # Amzar 9/9/2022 --> added more text to print statement\n",
    "print('TM corrected shape after filtering out null HNUM_STRT_TM: ', isp_corrected.shape) # Amzar 9/9/2022 --> added more text to print statement\n",
    "\n",
    "# REMOVE DUPLICATES. Line 1 (words) creates a list of ALL HNUM_STRT_TM. Line 2 (selection) only keeps unique HNUM_STRT_TM\n",
    "words = \" \".join(isp_corrected.HNUM_STRT_TM).split() \n",
    "selection = set(words)\n",
    "selection1 = list(selection)\n",
    "selection2 = pd.DataFrame(selection1)\n",
    "selection2.columns = ['MAPPED_HNUM_STRT_TM']\n",
    "selection2.head()\n",
    "\n",
    "\n",
    "MAPPED_STRT_HNUM_Df = astro_corrected.merge(selection2,left_on ='HNUM_STRT', right_on = 'MAPPED_HNUM_STRT_TM', how = 'inner')\n",
    "MAPPED_STRT_HNUM_Df.shape\n",
    "\n",
    "\n",
    "MAPPED_STRT_HNUM_Df.head()\n",
    "\n",
    "\n",
    "# Making sure that HOUSE_NO has valid value\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['HOUSE_NO'].notnull()]\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['HOUSE_NO']!= \"\"]\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['HOUSE_NO']!= \" \"]\n",
    "MAPPED_STRT_HNUM_Df.shape\n",
    "\n",
    "\n",
    "# Making sure that G_Street_Name_1 has valid value\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['Street_1'].notnull()]\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['Street_1']!= \"\"]\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['Street_1']!= \" \"]\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['Street_1']!= \"NAN\"]\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['Street_1']!= \"nan\"]\n",
    "MAPPED_STRT_HNUM_Df.shape\n",
    "\n",
    "# this step is to keep only ONE record for 1 address even if there are 2 Sources (Vendor or GAPI)\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df.sort_values(by='Source', ascending=False)\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df.drop_duplicates(subset=['ACCOUNT_NO','HOUSE_NO'],keep='first')\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df.drop_duplicates(subset='ACCOUNT_NO',keep='last')\n",
    "\n",
    "print('P1 SDU MAPPED_STRT_HNUM_Df - Shape: ', MAPPED_STRT_HNUM_Df.shape, ' & Unique Acc_No: ', MAPPED_STRT_HNUM_Df.ACCOUNT_NO.nunique()) # Amzar 9/9/2022 --> added more text to print statement \n",
    "\n",
    "P1_SDU = MAPPED_STRT_HNUM_Df.copy() # Amzar 9/9/2022 --> added copy() to create an explicit copy\n",
    "print('P1_SDU dataframe shape: ', P1_SDU.shape) # Amzar 9/9/2022 --> added new print statement to see shape of P1_SDU variable\n",
    "\n",
    "# ### Generating UAMS format and getting ServiceType\n",
    "\n",
    "STRT_P1 = MAPPED_STRT_HNUM_Df.copy() # Amzar 9/9/2022 --> added copy() to create an explicit copy\n",
    "print('P1 SDU STRT_P1 dataframe shape: ', STRT_P1.shape) # Amzar 9/9/2022 --> added new print statement to see shape of STRT_P1 variable\n",
    "\n",
    "STRT_P1['Street_1'] = STRT_P1['Street_1'].astype(str)\n",
    "\n",
    "STRT_P1.reset_index(inplace=True, drop=True)\n",
    "test = STRT_P1.loc[STRT_P1['Street_1'].apply(lambda x: x.startswith('AA')), :].index # Amzar 9/9/2022 --> added loc statement\n",
    "test = list(test)\n",
    "\n",
    "STRT_P1.loc[test,'Street_1'] = ''\n",
    "\n",
    "STRT_P1.loc[STRT_P1['match']=='Match','Street_2'] = ''\n",
    "STRT_P1[STRT_P1['match']=='Match']\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_street(item):\n",
    "\n",
    "    street_type = \"\"\n",
    "    \n",
    "    r1 = \"JALAN|LORONG|CHANGKAT|LAMAN|LAHAT|LEBUH|LEBUHRAYA|LENGKOK|LINGKARAN|PERSIARAN\"\n",
    "\n",
    "\n",
    "    m = re.search(r1,item)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "    return street_type        \n",
    "        \n",
    "STRT_P1[\"Street_Type_1\"] = STRT_P1[\"Street_1\"].apply(extract_street)\n",
    "STRT_P1[\"Street_Type_2\"] = STRT_P1[\"Street_2\"].map(str).apply(extract_street)\n",
    "STRT_P1.head()\n",
    "\n",
    "street_type_list = ['JALAN ', 'LORONG ','CHANGKAT ', 'LAMAN ', 'LAHAT ', 'LEBUH ', 'LEBUHRAYA ', 'LENGKOK ','LINGKARAN ', 'PERSIARAN ' ]\n",
    "STRT_P1[\"Street_1_New\"] = STRT_P1[\"Street_1\"].str.replace('|'.join(street_type_list), '')\n",
    "\n",
    "STRT_P1[\"Street_2\"] = STRT_P1[\"Street_2\"].str.upper()\n",
    "STRT_P1[\"Street_2_New\"] = STRT_P1[\"Street_2\"].str.replace('|'.join(street_type_list), '')\n",
    "STRT_P1.head()\n",
    "\n",
    "# Getting the ServiceType\n",
    "service_list = isp_corrected.loc[:, ['ServiceType','HNUM_STRT_TM']].drop_duplicates() # Amzar 9/9/2022 --> added loc \n",
    "service_list[\"ServiceType\"] = service_list[\"ServiceType\"].str.upper()\n",
    "service_list = service_list[service_list['ServiceType']!='ERROR']\n",
    "\n",
    "\n",
    "New_fields1 = pd.merge(STRT_P1,service_list,left_on ='HNUM_STRT',right_on='HNUM_STRT_TM', how = 'left')\n",
    "New_fields1.info()\n",
    "\n",
    "\n",
    "#MDU NEW\n",
    "New_fields2 = New_fields1[['ACCOUNT_NO','service_add_objid','ASTRO_HOUSE_NO1',\n",
    "                           'Combined_Building','Street_Type_1','Street_1_New','Standard_Building_Name', \n",
    "                           'Street_Type_2','Street_2_New','AREA','POSTCODE','STD_CITY','ASTRO_STATE', 'ServiceType','HNUM_STRT_TM']]\n",
    "\n",
    "\n",
    "New_fields2.loc[:, 'Servicable']= str(ISP_Name) # Amzar 9/9/2022 --> added loc \n",
    "\n",
    "\n",
    "# New_fields3 = New_fields2.drop_duplicates(subset= 'ACCOUNT_NO', keep = 'first')\n",
    "New_fields3 = New_fields2.sort_values(['ServiceType']).drop_duplicates(subset= 'ACCOUNT_NO', keep = 'first')\n",
    "astro_cleaned = New_fields3.copy() # Amzar 9/9/2022 --> added copy()\n",
    "print('P1 SDU astro_cleaned shape: ', astro_cleaned.shape, '& New_fields3 shape: ', New_fields3.shape) # Amzar 9/9/2022 --> added new print statement to compare\n",
    "\n",
    "\n",
    "# Fix HOUSE_NO that are converted to date\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['ASTRO_HOUSE_NO1'] \n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"JAN-\",\"01-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-JAN\",\"-01\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Jan-\",\"01-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Jan\",\"-01\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"FEB-\",\"02-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-FEB\",'-02', case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Feb-\",\"02-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Feb\",\"-02\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"MAR-\",'03-', case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-MAR\",\"-03\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Mar-\",'03-', case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Mar\",\"-03\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"APR-\",\"04-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-APR\",\"-04\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Apr-\",\"04-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Apr\",\"-04\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"MAY-\",\"05-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-MAY\",\"-05\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"May-\",\"05-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-May\",\"-05\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"JUN-\",\"06-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-JUN\",\"-06\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Jun-\",\"06-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Jun\",\"-06\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"JUL-\",\"07-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-JUL\",\"-07\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Jul-\",\"07-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Jul\",\"-07\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"AUG-\",'08-', case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-AUG\",\"-08\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Aug-\",'08-', case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Aug\",\"-08\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"SEP-\",\"09-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-SEP\",\"-09\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Sep-\",\"09-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Sep\",\"-09\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"OCT-\",\"10-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-OCT\",\"-10\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Oct-\",\"10-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Oct\",\"-10\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"NOV-\",\"11-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-NOV\",\"-11\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Nov-\",\"11-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Nov\",\"-11\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"DEC-\",\"12-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-DEC\",\"-12\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Dec-\",\"12-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Dec\",\"-12\", case = False)\n",
    "\n",
    "# Fix HOUSE_NO that are converted to date (DD/MM/YYYY format)\n",
    "# Filter date HOUSE_NO\n",
    "date_house = astro_cleaned[astro_cleaned['HOUSE_NO'].str.match('^([0-2][0-9]|(3)[0-1])(\\/)(((0)[0-9])|((1)[0-2]))(\\/)\\d{4}$')== True]\n",
    "# Spliting the HOUSE_NO\n",
    "date_house.loc[:, 'block'] = (date_house.HOUSE_NO.str[0:2]) # Amzar 9/9/2022 --> added loc \n",
    "date_house.loc[:, 'floor'] = (date_house.HOUSE_NO.str[3:5]) # Amzar 9/9/2022 --> added loc \n",
    "date_house.loc[:, 'unit'] = (date_house.HOUSE_NO.str[8:10]) # Amzar 9/9/2022 --> added loc \n",
    "# Combine the split HOUSE_NO with -\n",
    "date_house.loc[:, 'HOUSE_NO_ASTRO'] = date_house['block'] + \"-\" + date_house['floor'] + \"-\" + date_house['unit'] # Amzar 9/9/2022 --> added loc \n",
    "# Filter not date HOUSE_NO\n",
    "not_date_house = astro_cleaned[~(astro_cleaned['HOUSE_NO'].str.match('^([0-2][0-9]|(3)[0-1])(\\/)(((0)[0-9])|((1)[0-2]))(\\/)\\d{4}$')== True)]\n",
    "not_date_house.loc[:, 'HOUSE_NO_ASTRO'] = not_date_house['HOUSE_NO'] # Amzar 9/9/2022 --> added loc \n",
    "not_date_house.head()\n",
    "# Append the 2 df again\n",
    "frame = [date_house,not_date_house]\n",
    "astro_cleaned = pd.concat(frame)\n",
    "astro_cleaned.shape\n",
    "\n",
    "# Remove additional column created to combine HOUSE_NO\n",
    "astro_cleaned = astro_cleaned.drop(['block','floor','unit'],axis=1)\n",
    "astro_cleaned.info()\n",
    "\n",
    "\n",
    "\n",
    "astro_cleaned['ASTRO_HOUSE_NO1']= astro_cleaned['HOUSE_NO_ASTRO'].str.pad(width=10)\n",
    "\n",
    "\n",
    "#MDU NEW\n",
    "astro_cleaned2 = astro_cleaned[['ACCOUNT_NO','service_add_objid', 'ASTRO_HOUSE_NO1', \n",
    "                                   'Combined_Building','Street_Type_1','Street_1_New','Street_Type_2',\n",
    "                                   'Street_2_New',  'AREA','STD_CITY' ,'POSTCODE', 'ASTRO_STATE',\n",
    "                                   'Standard_Building_Name',\n",
    "                                   'ServiceType', 'Servicable', 'HNUM_STRT_TM']]\n",
    "\n",
    "\n",
    "UAMS_SDU_Base = astro_cleaned2.copy() # Amzar 9/9/2022 --> added copy() \n",
    "print('P1 SDU UAMS_SDU_BASE df shape: ', UAMS_SDU_Base.shape, ' & astro_cleaned2 df shape: ', astro_cleaned2.shape) # Amzar 9/9/2022 --> added new print statement to compare\n",
    "\n",
    "UAMS_SDU_Base.loc[:, 'ACCOUNT_NO'] = UAMS_SDU_Base.loc[:, 'ACCOUNT_NO'].astype(str) # Amzar 9/9/2022 --> added loc \n",
    "UAMS_SDU_Base.loc[:, 'ACCOUNT_NO'] = UAMS_SDU_Base.loc[:, 'ACCOUNT_NO'].str.replace('\\.0','', case = False) # Amzar 9/9/2022 --> added loc \n",
    "\n",
    "print('P1 SDU UAMS_SDU_Base shape after converting ACC_NO col to str type: ', UAMS_SDU_Base.shape) # Amzar 9/9/2022 --> added more text to the print statement\n",
    "\n",
    "UAMS_SDU_Base = UAMS_SDU_Base.drop_duplicates(subset=['ACCOUNT_NO'], keep='first')\n",
    "print('P1 SDU UAMS_SDU_Base shape AFTER dedupe on ACC_NO, keep first: ', UAMS_SDU_Base.shape) # Amzar 9/9/2022 --> added more text to the print statement\n",
    "\n",
    "\n",
    "\n",
    "UAMS_SDU_Base = UAMS_SDU_Base.rename({'ASTRO_HOUSE_NO1':'House_No', \n",
    "                                      'ACCOUNT_NO': 'Account_No'}, axis=1)\n",
    "\n",
    "\n",
    "#UAMS_SDU_Base.to_csv('UAMS_Format_stndrd_'+str(ISP_Name)+'_P1_SDU.csv') # Save in pipeline bucket - to be used in UAMS generation\n",
    "print('this is p1 sdu: ', UAMS_SDU_Base.shape)\n",
    "wr.s3.to_csv(df = UAMS_SDU_Base, path = uams_sdu_path + 'UAMS_Format_stndrd_' + str(ISP_Name)+ '_P1_SDU.csv.gz', compression='gzip', index=False) # 18/11/22: AFTER running the job, decided to add this line to generate a file for easier automation. 5/12/22: added gz\n",
    "wr.s3.to_csv(df = UAMS_SDU_Base, path = uams_sdu_path + 'historical_folder/UAMS_Format_stndrd_' + str(ISP_Name)+ '_P1_SDU_' + str(curr_date) + '.csv.gz', compression='gzip', index=False) # 18/11/22: added underscore after 'MDU' and AFTER running it to generate the files, decided to add the dated one to historical_folder \n",
    "\n",
    "\n",
    "# Remove the mapped account no\n",
    "MAPPED_STRT_HNUM_Df_list = list(MAPPED_STRT_HNUM_Df['ACCOUNT_NO'])\n",
    "astro_unmapped = astro_corrected.loc[~astro_corrected['ACCOUNT_NO'].isin(MAPPED_STRT_HNUM_Df_list), :] # Amzar 9/9/2022 --> added loc \n",
    "print('Astro Corrected shape right before end of P1 MDU mapping step and generating astro_unmapped: ', astro_corrected.shape) # Amzar 9/9/2022 --> added new print statement\n",
    "print('After P1 SDU mapping step --> Astro Unmapped Shape : ', astro_unmapped.shape, ' & no of Unique Account No: ', astro_unmapped.ACCOUNT_NO.nunique()) # Amzar 9/9/2022 --> added more text to the print statement\n",
    "\n",
    "# --> what is this below step for? There does not seem to be a use later on in this job. Maybe it's leftover from Maryam's local notebook\n",
    "MDU_IN_SDU = UAMS_SDU_Base[UAMS_SDU_Base['Standard_Building_Name']!='']\n",
    "MDU_IN_SDU.shape\n",
    "\n",
    "\n",
    "# ### ---------------------------------------------------------- P2 Mapping - SDU ----------------------------------------------------------\n",
    "\n",
    "## Using the unmapped base from P1 SDU mapping as the new astro_corrected\n",
    "astro_corrected = astro_unmapped.copy() # Amzar 9/9/2022 --> added copy()\n",
    "\n",
    "isp_corrected.info()\n",
    "\n",
    "print('Start of P2 SDU Mapping. First, check TM Corrected shape: ', isp_corrected.shape) # Amzar 9/9/2022 --> added more text to print statement \n",
    "print('astro_corrected shape for P2 SDU Mapping (unmapped base after P1 SDU Mapping): ', astro_corrected.shape) # Amzar 9/9/2022 --> added more text to print statement \n",
    "\n",
    "# astro_corrected.ACCOUNT_NO.nnunique()\n",
    "\n",
    "\n",
    "# Add new column in astro_corrected -- HOUSE_NO + G_Street_Name_1 + G_City = HNUM_STRT\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected[\"Street_1\"].map(str) + \" ,\" +                             astro_corrected[\"STD_CITY\"].map(str)\n",
    "astro_corrected.tail()\n",
    "\n",
    "\n",
    "# Clean HNUM_STRT column\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected['HNUM_STRT'].str.replace('nan ','', case = False)\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected['HNUM_STRT'].str.replace('[,.]','', case = False)\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected[\"HNUM_STRT\"].str.replace(\" \",\"\")\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected[\"HNUM_STRT\"].str.replace(\"\\.\",\"\")\n",
    "astro_corrected[\"HNUM_STRT\"] = astro_corrected[\"HNUM_STRT\"].str.replace(\",\",\"\")\n",
    "\n",
    "print('Astro corrected shape after cleaning address columns & creating HNUM_STRT: ', astro_corrected.shape) # Amzar 9/9/2022 --> added more text to print statement \n",
    "\n",
    "\n",
    "# Capitalize HNUM_STRT\n",
    "astro_corrected['HNUM_STRT'] = astro_corrected['HNUM_STRT'].str.upper() \n",
    "\n",
    "\n",
    "astro_corrected.head()\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "# Add new column in isp_corrected -- HouseNo + G_Street_Name_1 + G_City = HNUM_STRT_TM\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected[\"Street_1\"].map(str) + \" ,\" +                             isp_corrected[\"STD_CITY\"].map(str)\n",
    "isp_corrected.head()\n",
    "\n",
    "\n",
    "# Clean HNUM_STRT_TM column\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected['HNUM_STRT_TM'].str.replace('nan ','', case = False)\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected['HNUM_STRT_TM'].str.replace('[,.]','', case = False)\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected[\"HNUM_STRT_TM\"].str.replace(\" \",\"\")\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected[\"HNUM_STRT_TM\"].str.replace(\",\",\"\")\n",
    "isp_corrected[\"HNUM_STRT_TM\"] = isp_corrected[\"HNUM_STRT_TM\"].str.replace(\"\\.\",\"\")\n",
    "\n",
    "print('TM corrected shape after cleaning address columns & creating HNUM_STRT_TM: ', isp_corrected.shape) # Amzar 9/9/2022 --> added more text to print statement\n",
    "\n",
    "\n",
    "# Capitalize HNUM_STRT_TM\n",
    "isp_corrected['HNUM_STRT_TM'] = isp_corrected['HNUM_STRT_TM'].str.upper() \n",
    "\n",
    "\n",
    "# Remove nulls in HNUM_STRT and HNUM_STRT_TM\n",
    "astro_corrected = astro_corrected[astro_corrected.HNUM_STRT.notnull()] # Amzar 9/9/2022 --> this is the last transformation to astro_corrected before the end of P1 MDU step. So before going to P1 SDU mapping, we may actually be missing some addresses as we transfer astro_corrected to astro_unmapped\n",
    "isp_corrected = isp_corrected[isp_corrected.HNUM_STRT_TM.notnull()]\n",
    "\n",
    "print('Astro corrected shape after filtering out null HNUM_STRT: ', astro_corrected.shape) # Amzar 9/9/2022 --> added more text to print statement\n",
    "print('TM corrected shape after filtering out null HNUM_STRT_TM: ', isp_corrected.shape) # Amzar 9/9/2022 --> added more text to print statement\n",
    "\n",
    "\n",
    "words = \" \".join(isp_corrected.HNUM_STRT_TM).split() \n",
    "selection = set(words)\n",
    "selection1 = list(selection)\n",
    "selection2 = pd.DataFrame(selection1)\n",
    "selection2.columns = ['MAPPED_HNUM_STRT_TM']\n",
    "selection2.head()\n",
    "\n",
    "\n",
    "MAPPED_STRT_HNUM_Df = astro_corrected.merge(selection2,left_on ='HNUM_STRT', right_on = 'MAPPED_HNUM_STRT_TM', how = 'inner')\n",
    "MAPPED_STRT_HNUM_Df.shape\n",
    "\n",
    "MAPPED_STRT_HNUM_Df.head()\n",
    "\n",
    "\n",
    "# Making sure that G_Street_Name_1 has valid value\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['Street_1'].notnull()]\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['Street_1']!= \"\"]\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['Street_1']!= \" \"]\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['Street_1']!= \"NAN\"]\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df[MAPPED_STRT_HNUM_Df['Street_1']!= \"nan\"]\n",
    "MAPPED_STRT_HNUM_Df.shape\n",
    "\n",
    "# this step is to keep only ONE record for 1 address even if there are 2 Sources (Vendor or GAPI)\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df.sort_values(by='Source', ascending=False)\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df.drop_duplicates(subset=['ACCOUNT_NO','HOUSE_NO'],keep='first')\n",
    "MAPPED_STRT_HNUM_Df = MAPPED_STRT_HNUM_Df.drop_duplicates(subset='ACCOUNT_NO',keep='last')\n",
    "\n",
    "\n",
    "print('P2 SDU MAPPED_STRT_HNUM_Df - Shape: ', MAPPED_STRT_HNUM_Df.shape, ' & Unique Acc_No: ', MAPPED_STRT_HNUM_Df.ACCOUNT_NO.nunique()) # Amzar 9/9/2022 --> added more text to print statement \n",
    "\n",
    "P2_SDU = MAPPED_STRT_HNUM_Df.copy() # Amzar 9/9/2022 --> added copy() to create an explicit copy\n",
    "print('P2_SDU dataframe shape: ', P2_SDU.shape) # Amzar 9/9/2022 --> added new print statement to see shape of P1_SDU variable\n",
    "\n",
    "\n",
    "# ### Generating UAMS format and getting ServiceType\n",
    "\n",
    "STRT_P1 = MAPPED_STRT_HNUM_Df.copy() # Amzar 9/9/2022 --> added copy() to create an explicit copy\n",
    "print('P2 SDU STRT_P1 dataframe shape: ', STRT_P1.shape) # Amzar 9/9/2022 --> added new print statement to see shape of STRT_P1 variable\n",
    "\n",
    "STRT_P1['Street_1'] = STRT_P1['Street_1'].astype(str)\n",
    "\n",
    "STRT_P1.reset_index(inplace=True, drop=True)\n",
    "test = STRT_P1.loc[STRT_P1['Street_1'].apply(lambda x: x.startswith('AA')), :].index # Amzar 9/9/2022 --> added loc statement\n",
    "test = list(test)\n",
    "\n",
    "STRT_P1.loc[test,'Street_1'] = ''\n",
    "\n",
    "STRT_P1.loc[STRT_P1['match']=='Match','Street_2'] = ''\n",
    "STRT_P1[STRT_P1['match']=='Match']\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_street(item):\n",
    "\n",
    "    street_type = \"\"\n",
    "    \n",
    "    r1 = \"JALAN|LORONG|CHANGKAT|LAMAN|LAHAT|LEBUH|LEBUHRAYA|LENGKOK|LINGKARAN|PERSIARAN\"\n",
    "\n",
    "\n",
    "    m = re.search(r1,item)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "    return street_type        \n",
    "        \n",
    "STRT_P1[\"Street_Type_1\"] = STRT_P1[\"Street_1\"].apply(extract_street)\n",
    "STRT_P1[\"Street_Type_2\"] = STRT_P1[\"Street_2\"].map(str).apply(extract_street)\n",
    "STRT_P1.head()\n",
    "\n",
    "street_type_list = ['JALAN ', 'LORONG ','CHANGKAT ', 'LAMAN ', 'LAHAT ', 'LEBUH ', 'LEBUHRAYA ', 'LENGKOK ','LINGKARAN ', 'PERSIARAN ' ]\n",
    "STRT_P1[\"Street_1_New\"] = STRT_P1[\"Street_1\"].str.replace('|'.join(street_type_list), '')\n",
    "\n",
    "STRT_P1[\"Street_2\"] = STRT_P1[\"Street_2\"].str.upper()\n",
    "STRT_P1[\"Street_2_New\"] = STRT_P1[\"Street_2\"].str.replace('|'.join(street_type_list), '')\n",
    "STRT_P1.head()\n",
    "\n",
    "# Getting the ServiceType\n",
    "service_list = isp_corrected.loc[:, ['ServiceType','HNUM_STRT_TM']].drop_duplicates() # Amzar 9/9/2022 --> added loc \n",
    "service_list[\"ServiceType\"] = service_list[\"ServiceType\"].str.upper()\n",
    "service_list = service_list[service_list['ServiceType']!='ERROR']\n",
    "\n",
    "\n",
    "New_fields1 = pd.merge(STRT_P1,service_list,left_on ='HNUM_STRT',right_on='HNUM_STRT_TM', how = 'left')\n",
    "New_fields1.info()\n",
    "\n",
    "\n",
    "#MDU NEW\n",
    "New_fields2 = New_fields1[['ACCOUNT_NO','service_add_objid','ASTRO_HOUSE_NO1',\n",
    "                           'Combined_Building','Street_Type_1','Street_1_New','Standard_Building_Name', \n",
    "                           'Street_Type_2','Street_2_New','AREA','POSTCODE','STD_CITY','ASTRO_STATE', 'ServiceType','HNUM_STRT_TM']]\n",
    "\n",
    "\n",
    "New_fields2.loc[:, 'Servicable']= str(ISP_Name) # Amzar 9/9/2022 --> added loc \n",
    "\n",
    "\n",
    "# New_fields3 = New_fields2.drop_duplicates(subset= 'ACCOUNT_NO', keep = 'first')\n",
    "New_fields3 = New_fields2.sort_values(['ServiceType']).drop_duplicates(subset= 'ACCOUNT_NO', keep = 'first')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "astro_cleaned = New_fields3.copy() # Amzar 9/9/2022 --> added copy()\n",
    "print('P2 SDU astro_cleaned shape: ', astro_cleaned.shape, '& New_fields3 shape: ', New_fields3.shape) # Amzar 9/9/2022 --> added new print statement to compare\n",
    "\n",
    "\n",
    "# Fix HOUSE_NO that are converted to date\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['ASTRO_HOUSE_NO1'] \n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"JAN-\",\"01-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-JAN\",\"-01\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Jan-\",\"01-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Jan\",\"-01\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"FEB-\",\"02-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-FEB\",'-02', case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Feb-\",\"02-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Feb\",\"-02\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"MAR-\",'03-', case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-MAR\",\"-03\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Mar-\",'03-', case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Mar\",\"-03\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"APR-\",\"04-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-APR\",\"-04\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Apr-\",\"04-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Apr\",\"-04\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"MAY-\",\"05-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-MAY\",\"-05\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"May-\",\"05-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-May\",\"-05\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"JUN-\",\"06-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-JUN\",\"-06\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Jun-\",\"06-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Jun\",\"-06\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"JUL-\",\"07-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-JUL\",\"-07\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Jul-\",\"07-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Jul\",\"-07\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"AUG-\",'08-', case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-AUG\",\"-08\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Aug-\",'08-', case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Aug\",\"-08\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"SEP-\",\"09-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-SEP\",\"-09\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Sep-\",\"09-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Sep\",\"-09\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"OCT-\",\"10-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-OCT\",\"-10\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Oct-\",\"10-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Oct\",\"-10\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"NOV-\",\"11-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-NOV\",\"-11\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Nov-\",\"11-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Nov\",\"-11\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"DEC-\",\"12-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-DEC\",\"-12\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"Dec-\",\"12-\", case = False)\n",
    "astro_cleaned['HOUSE_NO'] = astro_cleaned['HOUSE_NO'].str.replace(\"-Dec\",\"-12\", case = False)\n",
    "\n",
    "# Fix HOUSE_NO that are converted to date (DD/MM/YYYY format)\n",
    "# Filter date HOUSE_NO\n",
    "date_house = astro_cleaned[astro_cleaned['HOUSE_NO'].str.match('^([0-2][0-9]|(3)[0-1])(\\/)(((0)[0-9])|((1)[0-2]))(\\/)\\d{4}$')== True]\n",
    "# Spliting the HOUSE_NO\n",
    "date_house.loc[:, 'block'] = (date_house.HOUSE_NO.str[0:2]) # Amzar 9/9/2022 --> added loc \n",
    "date_house.loc[:, 'floor'] = (date_house.HOUSE_NO.str[3:5]) # Amzar 9/9/2022 --> added loc \n",
    "date_house.loc[:, 'unit'] = (date_house.HOUSE_NO.str[8:10]) # Amzar 9/9/2022 --> added loc \n",
    "# Combine the split HOUSE_NO with -\n",
    "date_house.loc[:, 'HOUSE_NO_ASTRO'] = date_house['block'] + \"-\" + date_house['floor'] + \"-\" + date_house['unit'] # Amzar 9/9/2022 --> added loc \n",
    "# Filter not date HOUSE_NO\n",
    "not_date_house = astro_cleaned[~(astro_cleaned['HOUSE_NO'].str.match('^([0-2][0-9]|(3)[0-1])(\\/)(((0)[0-9])|((1)[0-2]))(\\/)\\d{4}$')== True)]\n",
    "not_date_house.loc[:, 'HOUSE_NO_ASTRO'] = not_date_house['HOUSE_NO'] # Amzar 9/9/2022 --> added loc \n",
    "not_date_house.head()\n",
    "# Append the 2 df again\n",
    "frame = [date_house,not_date_house]\n",
    "astro_cleaned = pd.concat(frame)\n",
    "astro_cleaned.shape\n",
    "\n",
    "# Remove additional column created to combine HOUSE_NO\n",
    "astro_cleaned = astro_cleaned.drop(['block','floor','unit'],axis=1)\n",
    "astro_cleaned.info()\n",
    "\n",
    "\n",
    "\n",
    "astro_cleaned['ASTRO_HOUSE_NO1']= astro_cleaned['HOUSE_NO_ASTRO'].str.pad(width=10)\n",
    "\n",
    "\n",
    "#MDU NEW\n",
    "astro_cleaned2 = astro_cleaned[['ACCOUNT_NO','service_add_objid', 'ASTRO_HOUSE_NO1', \n",
    "                                   'Combined_Building','Street_Type_1','Street_1_New','Street_Type_2',\n",
    "                                   'Street_2_New',  'AREA','STD_CITY' ,'POSTCODE', 'ASTRO_STATE',\n",
    "                                   'Standard_Building_Name',\n",
    "                                   'ServiceType', 'Servicable', 'HNUM_STRT_TM']]\n",
    "\n",
    "\n",
    "UAMS_MDU_Base = astro_cleaned2.copy() # Amzar 9/9/2022 --> added copy() \n",
    "print('P2 SDU UAMS_MDU_BASE (might need to change df name) shape: ', UAMS_MDU_Base.shape, ' & astro_cleaned2 df shape: ', astro_cleaned2.shape) # Amzar 9/9/2022 --> added new print statement to compare\n",
    "\n",
    "UAMS_MDU_Base.loc[:, 'ACCOUNT_NO'] = UAMS_MDU_Base['ACCOUNT_NO'].astype(str) # Amzar 9/9/2022 --> added loc \n",
    "UAMS_MDU_Base.loc[:, 'ACCOUNT_NO'] = UAMS_MDU_Base['ACCOUNT_NO'].str.replace('\\.0','', case = False) # Amzar 9/9/2022 --> added loc \n",
    "\n",
    "print('P2 SDU UAMS_MDU_BASE shape after converting ACC_NO col to str type: ', UAMS_MDU_Base.shape) # Amzar 9/9/2022 --> added more text to the print statement\n",
    "\n",
    "# UAMS_MDU_Base = UAMS_MDU_Base.drop_duplicates(subset=['ACCOUNT_NO'], keep='first')\n",
    "# print(UAMS_MDU_Base.shape) # Amzar 9/9/2022 --> commented out\n",
    "print('For P2 SDU, there is no dedupe on ACC_NO as it is the final mapping step') # Amzar 9/9/2022 --> added new print statement to describe why no de-dupe\n",
    "\n",
    "\n",
    "UAMS_MDU_Base=UAMS_MDU_Base.rename({'ASTRO_HOUSE_NO1':'House_No', \n",
    "                                      'ACCOUNT_NO': 'Account_No'}, axis=1)\n",
    "\n",
    "\n",
    "print('this is p2 sdu: ', UAMS_MDU_Base.shape)\n",
    "#UAMS_MDU_Base.to_csv('UAMS_Format_stndrd_'+str(ISP_Name)+'_P2_SDU.csv') # Save in pipeline bucket - to be used in UAMS generation\n",
    "wr.s3.to_csv(df = UAMS_MDU_Base, path = uams_sdu_path + 'UAMS_Format_stndrd_' + str(ISP_Name)+ '_P2_SDU.csv.gz', compression='gzip', index=False) # 18/11/22: AFTER running the job, decided to add this line to generate a file for easier automation. 5/12/22: added gz\n",
    "wr.s3.to_csv(df = UAMS_MDU_Base, path = uams_sdu_path + 'historical_folder/UAMS_Format_stndrd_' + str(ISP_Name)+ '_P2_SDU_' + str(curr_date) + '.csv.gz', compression='gzip', index=False) # 18/11/22: added underscore after 'MDU' and AFTER running it to generate the files, decided to add the dated one to historical_folder \n",
    "\n",
    "# Amzar 9/9/2022 --> Added this paragraph to see how many acc no left unmapped (copied from P1 SDU)\n",
    "MAPPED_STRT_HNUM_Df_list = list(MAPPED_STRT_HNUM_Df['ACCOUNT_NO'])\n",
    "astro_unmapped = astro_corrected.loc[~astro_corrected['ACCOUNT_NO'].isin(MAPPED_STRT_HNUM_Df_list), :] \n",
    "print('Astro Corrected shape right before end of P1 SDU mapping step and generating astro_unmapped: ', astro_corrected.shape) \n",
    "print('After P2 SDU mapping step --> Final leftover Astro Unmapped Shape : ', astro_unmapped.shape, ' & no of Unique Account No: ', astro_unmapped.ACCOUNT_NO.nunique())\n",
    "\n",
    "usage = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "print('[debug] memory usage is (Megabytes):')\n",
    "print(usage)\n",
    "    \n",
    "print('end')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
